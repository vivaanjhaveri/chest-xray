{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>...</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Hernia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>-0.187979</td>\n",
       "      <td>0.043346</td>\n",
       "      <td>-0.005866</td>\n",
       "      <td>-0.180116</td>\n",
       "      <td>-0.216491</td>\n",
       "      <td>0.181554</td>\n",
       "      <td>0.053038</td>\n",
       "      <td>-0.242247</td>\n",
       "      <td>-0.196432</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>-0.173904</td>\n",
       "      <td>0.104313</td>\n",
       "      <td>-0.027356</td>\n",
       "      <td>0.061408</td>\n",
       "      <td>-0.213318</td>\n",
       "      <td>0.297480</td>\n",
       "      <td>0.328217</td>\n",
       "      <td>-0.221172</td>\n",
       "      <td>-0.119333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>-0.156875</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>-0.183765</td>\n",
       "      <td>0.010118</td>\n",
       "      <td>-0.242131</td>\n",
       "      <td>0.274381</td>\n",
       "      <td>-0.061397</td>\n",
       "      <td>0.085868</td>\n",
       "      <td>-0.178546</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>-0.197439</td>\n",
       "      <td>0.289834</td>\n",
       "      <td>-0.143378</td>\n",
       "      <td>0.238400</td>\n",
       "      <td>-0.159914</td>\n",
       "      <td>0.132197</td>\n",
       "      <td>-0.086083</td>\n",
       "      <td>-0.187805</td>\n",
       "      <td>-0.050839</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>-0.123684</td>\n",
       "      <td>-0.005224</td>\n",
       "      <td>-0.083841</td>\n",
       "      <td>0.031354</td>\n",
       "      <td>-0.202258</td>\n",
       "      <td>0.914344</td>\n",
       "      <td>0.074426</td>\n",
       "      <td>-0.222060</td>\n",
       "      <td>-0.199442</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2063 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index        x0        x1        x2        x3        x4  \\\n",
       "0  00000001_000.png -0.187979  0.043346 -0.005866 -0.180116 -0.216491   \n",
       "1  00000001_001.png -0.173904  0.104313 -0.027356  0.061408 -0.213318   \n",
       "2  00000001_002.png -0.156875  0.002193 -0.183765  0.010118 -0.242131   \n",
       "3  00000002_000.png -0.197439  0.289834 -0.143378  0.238400 -0.159914   \n",
       "4  00000003_000.png -0.123684 -0.005224 -0.083841  0.031354 -0.202258   \n",
       "\n",
       "         x5        x6        x7        x8  ...  Edema  Emphysema  Fibrosis  \\\n",
       "0  0.181554  0.053038 -0.242247 -0.196432  ...      0          0         0   \n",
       "1  0.297480  0.328217 -0.221172 -0.119333  ...      0          1         0   \n",
       "2  0.274381 -0.061397  0.085868 -0.178546  ...      0          0         0   \n",
       "3  0.132197 -0.086083 -0.187805 -0.050839  ...      0          0         0   \n",
       "4  0.914344  0.074426 -0.222060 -0.199442  ...      0          0         0   \n",
       "\n",
       "   Effusion  Pneumonia  Pleural_Thickening  Cardiomegaly  Nodule  Mass  Hernia  \n",
       "0         0          0                   0             1       0     0       0  \n",
       "1         0          0                   0             1       0     0       0  \n",
       "2         1          0                   0             1       0     0       0  \n",
       "3         0          0                   0             0       0     0       0  \n",
       "4         0          0                   0             0       0     0       1  \n",
       "\n",
       "[5 rows x 2063 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"xray_input.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/5q/fmks3y_x73d1rdwpr7g2y9c40000gn/T/ipykernel_61833/3290264247.py:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  X = df.filter(regex='^x\\d+')\n",
      "/var/folders/5q/fmks3y_x73d1rdwpr7g2y9c40000gn/T/ipykernel_61833/3290264247.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y['no_finding'] = (y.sum(axis=1) == 0).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total explained variance with 100 components: 0.7999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming df is your dataframe with features x0-x2048 and the 14 label columns\n",
    "# Separate features and labels\n",
    "X = df.filter(regex='^x\\d+')\n",
    "y = df[[\"Atelectasis\", \"Consolidation\", \"Infiltration\", \"Pneumothorax\", \"Edema\",\n",
    "       \"Emphysema\", \"Fibrosis\", \"Effusion\", \"Pneumonia\", \"Pleural_Thickening\",\n",
    "       \"Cardiomegaly\", \"Nodule\", \"Mass\", \"Hernia\"]]\n",
    "\n",
    "# Create a column indicating if all labels are 0 (no findings)\n",
    "y['no_finding'] = (y.sum(axis=1) == 0).astype(int)\n",
    "\n",
    "# Split the data first to avoid data leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y.drop('no_finding', axis=1), \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y['no_finding']\n",
    ")\n",
    "\n",
    "# Scale the data before applying PCA\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA - try reducing to ~100-200 components to start\n",
    "# You can adjust n_components based on your RAM constraints and the variance explained\n",
    "n_components = 100  # Starting point, adjust as needed\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Check explained variance to ensure we've captured enough information\n",
    "explained_variance = np.sum(pca.explained_variance_ratio_)\n",
    "print(f\"Total explained variance with {n_components} components: {explained_variance:.4f}\")\n",
    "\n",
    "# Now proceed with your balanced sampling as before\n",
    "no_findings = y_train.sum(axis=1) == 0\n",
    "X_train_no_findings = X_train_pca[no_findings]\n",
    "\n",
    "y_train_no_findings = y_train[no_findings]\n",
    "X_train_findings = X_train_pca[~no_findings]\n",
    "y_train_findings = y_train[~no_findings]\n",
    "\n",
    "# Sample only a portion of the no-findings records\n",
    "sample_size = int(len(X_train_no_findings) * 0.05)  # Adjust ratio as needed\n",
    "indices = np.random.choice(len(X_train_no_findings), sample_size, replace=False)\n",
    "X_train_no_findings_sampled = X_train_no_findings[indices]\n",
    "y_train_no_findings_sampled = y_train_no_findings.iloc[indices]\n",
    "\n",
    "# Combine the sampled no-findings with all findings samples\n",
    "X_train_balanced = np.vstack([X_train_no_findings_sampled, X_train_findings])\n",
    "y_train_balanced = pd.concat([y_train_no_findings_sampled, y_train_findings])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.04101368e+00, -1.67271092e+00,  1.81884919e+00, ...,\n",
       "         6.08618858e-01,  7.55722704e-03,  1.70770134e-02],\n",
       "       [ 1.98795617e+01, -9.61303985e+00, -8.16642121e-01, ...,\n",
       "         2.60334443e-01, -7.39803742e-01, -1.45892705e+00],\n",
       "       [ 2.88719176e+01, -9.19336599e+00, -1.83663516e+01, ...,\n",
       "         1.03321812e+00,  2.38960929e+00,  2.21570140e+00],\n",
       "       ...,\n",
       "       [-4.22392115e+00,  8.18450975e+00, -9.07167896e-01, ...,\n",
       "        -1.68643287e+00, -1.38714688e+00, -9.43391533e-02],\n",
       "       [-1.17175822e+01,  1.53355860e+01, -1.14901236e+01, ...,\n",
       "        -2.28074792e+00, -1.31174074e+00,  1.73910727e+00],\n",
       "       [ 1.03327133e+01, -7.85361759e+00,  9.00489929e+00, ...,\n",
       "         5.31199018e-01,  2.04622045e+00, -4.64904208e-01]],\n",
       "      shape=(43821, 100))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Hernia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109454</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57193</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54404</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39768</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79030</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103080</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96763</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12878</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43821 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Atelectasis  Consolidation  Infiltration  Pneumothorax  Edema  \\\n",
       "109454            0              0             0             0      0   \n",
       "57193             0              0             0             0      0   \n",
       "54404             0              0             0             0      0   \n",
       "70381             0              0             0             0      0   \n",
       "24191             0              0             0             0      0   \n",
       "...             ...            ...           ...           ...    ...   \n",
       "39768             1              1             0             0      0   \n",
       "79030             1              1             1             0      0   \n",
       "103080            0              0             0             0      0   \n",
       "96763             0              0             1             0      0   \n",
       "12878             0              0             1             0      0   \n",
       "\n",
       "        Emphysema  Fibrosis  Effusion  Pneumonia  Pleural_Thickening  \\\n",
       "109454          0         0         0          0                   0   \n",
       "57193           0         0         0          0                   0   \n",
       "54404           0         0         0          0                   0   \n",
       "70381           0         0         0          0                   0   \n",
       "24191           0         0         0          0                   0   \n",
       "...           ...       ...       ...        ...                 ...   \n",
       "39768           0         0         0          0                   0   \n",
       "79030           0         1         1          0                   0   \n",
       "103080          1         0         0          0                   1   \n",
       "96763           0         0         0          0                   0   \n",
       "12878           0         0         0          0                   0   \n",
       "\n",
       "        Cardiomegaly  Nodule  Mass  Hernia  \n",
       "109454             0       0     0       0  \n",
       "57193              0       0     0       0  \n",
       "54404              0       0     0       0  \n",
       "70381              0       0     0       0  \n",
       "24191              0       0     0       0  \n",
       "...              ...     ...   ...     ...  \n",
       "39768              0       0     0       0  \n",
       "79030              0       0     1       0  \n",
       "103080             0       1     0       0  \n",
       "96763              0       0     0       0  \n",
       "12878              0       0     0       0  \n",
       "\n",
       "[43821 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(93993) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages (from seaborn) (2.2.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(81676) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(81677) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(81678) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(81679) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(81680) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(81681) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(81682) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(81683) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(81685) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(81687) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(91465) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(91468) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(91469) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(91470) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(91471) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(91472) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(91473) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(91474) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Atelectasis:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     20114\n",
      "           1       0.00      0.00      0.00      2310\n",
      "\n",
      "    accuracy                           0.90     22424\n",
      "   macro avg       0.45      0.50      0.47     22424\n",
      "weighted avg       0.80      0.90      0.85     22424\n",
      "\n",
      "Classification report for Consolidation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     21518\n",
      "           1       0.00      0.00      0.00       906\n",
      "\n",
      "    accuracy                           0.96     22424\n",
      "   macro avg       0.48      0.50      0.49     22424\n",
      "weighted avg       0.92      0.96      0.94     22424\n",
      "\n",
      "Classification report for Infiltration:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90     18442\n",
      "           1       0.55      0.00      0.00      3982\n",
      "\n",
      "    accuracy                           0.82     22424\n",
      "   macro avg       0.68      0.50      0.45     22424\n",
      "weighted avg       0.77      0.82      0.74     22424\n",
      "\n",
      "Classification report for Pneumothorax:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98     21377\n",
      "           1       0.00      0.00      0.00      1047\n",
      "\n",
      "    accuracy                           0.95     22424\n",
      "   macro avg       0.48      0.50      0.49     22424\n",
      "weighted avg       0.91      0.95      0.93     22424\n",
      "\n",
      "Classification report for Edema:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     21972\n",
      "           1       0.00      0.00      0.00       452\n",
      "\n",
      "    accuracy                           0.98     22424\n",
      "   macro avg       0.49      0.50      0.49     22424\n",
      "weighted avg       0.96      0.98      0.97     22424\n",
      "\n",
      "Classification report for Emphysema:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     21934\n",
      "           1       0.00      0.00      0.00       490\n",
      "\n",
      "    accuracy                           0.98     22424\n",
      "   macro avg       0.49      0.50      0.49     22424\n",
      "weighted avg       0.96      0.98      0.97     22424\n",
      "\n",
      "Classification report for Fibrosis:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     22075\n",
      "           1       0.00      0.00      0.00       349\n",
      "\n",
      "    accuracy                           0.98     22424\n",
      "   macro avg       0.49      0.50      0.50     22424\n",
      "weighted avg       0.97      0.98      0.98     22424\n",
      "\n",
      "Classification report for Effusion:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94     19710\n",
      "           1       0.62      0.00      0.01      2714\n",
      "\n",
      "    accuracy                           0.88     22424\n",
      "   macro avg       0.75      0.50      0.47     22424\n",
      "weighted avg       0.85      0.88      0.82     22424\n",
      "\n",
      "Classification report for Pneumonia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     22151\n",
      "           1       0.00      0.00      0.00       273\n",
      "\n",
      "    accuracy                           0.99     22424\n",
      "   macro avg       0.49      0.50      0.50     22424\n",
      "weighted avg       0.98      0.99      0.98     22424\n",
      "\n",
      "Classification report for Pleural_Thickening:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     21695\n",
      "           1       0.00      0.00      0.00       729\n",
      "\n",
      "    accuracy                           0.97     22424\n",
      "   macro avg       0.48      0.50      0.49     22424\n",
      "weighted avg       0.94      0.97      0.95     22424\n",
      "\n",
      "Classification report for Cardiomegaly:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     21872\n",
      "           1       0.00      0.00      0.00       552\n",
      "\n",
      "    accuracy                           0.98     22424\n",
      "   macro avg       0.49      0.50      0.49     22424\n",
      "weighted avg       0.95      0.98      0.96     22424\n",
      "\n",
      "Classification report for Nodule:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     21154\n",
      "           1       0.00      0.00      0.00      1270\n",
      "\n",
      "    accuracy                           0.94     22424\n",
      "   macro avg       0.47      0.50      0.49     22424\n",
      "weighted avg       0.89      0.94      0.92     22424\n",
      "\n",
      "Classification report for Mass:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     21297\n",
      "           1       0.00      0.00      0.00      1127\n",
      "\n",
      "    accuracy                           0.95     22424\n",
      "   macro avg       0.47      0.50      0.49     22424\n",
      "weighted avg       0.90      0.95      0.93     22424\n",
      "\n",
      "Classification report for Hernia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22384\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           1.00     22424\n",
      "   macro avg       0.50      0.50      0.50     22424\n",
      "weighted avg       1.00      1.00      1.00     22424\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/xray-svc/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train multi-label SVC with the reduced dimensionality data\n",
    "svc = SVC(kernel='rbf', C=0.1, probability=True)\n",
    "multi_svc = MultiOutputClassifier(svc, n_jobs=-1)\n",
    "multi_svc.fit(X_train_balanced, y_train_balanced)\n",
    "print(\"Finished Fit\")\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = multi_svc.predict(X_test_pca)\n",
    "\n",
    "# Evaluate per class\n",
    "for i, label in enumerate(y_train.columns):\n",
    "    print(f\"Classification report for {label}:\")\n",
    "    print(classification_report(y_test.iloc[:, i], y_pred[:, i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/5q/fmks3y_x73d1rdwpr7g2y9c40000gn/T/ipykernel_61833/3264559847.py:16: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  X = df.filter(regex='^x\\d+')\n",
      "/var/folders/5q/fmks3y_x73d1rdwpr7g2y9c40000gn/T/ipykernel_61833/3264559847.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y['no_finding'] = (y.sum(axis=1) == 0).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (89696, 2048), Test data shape: (22424, 2048)\n",
      "Scaling data...\n",
      "Applying PCA...\n",
      "Total explained variance with 100 components: 0.7999\n",
      "Handling class imbalance...\n",
      "Sampling 2414 from 48289 no-findings cases\n",
      "Balanced training data shape: (43821, 100)\n",
      "Class distribution in balanced training data:\n",
      "Atelectasis: 9249 positive cases (21.11%)\n",
      "Consolidation: 3761 positive cases (8.58%)\n",
      "Infiltration: 15912 positive cases (36.31%)\n",
      "Pneumothorax: 4255 positive cases (9.71%)\n",
      "Edema: 1851 positive cases (4.22%)\n",
      "Emphysema: 2026 positive cases (4.62%)\n",
      "Fibrosis: 1337 positive cases (3.05%)\n",
      "Effusion: 10603 positive cases (24.20%)\n",
      "Pneumonia: 1158 positive cases (2.64%)\n",
      "Pleural_Thickening: 2656 positive cases (6.06%)\n",
      "Cardiomegaly: 2224 positive cases (5.08%)\n",
      "Nodule: 5061 positive cases (11.55%)\n",
      "Mass: 4655 positive cases (10.62%)\n",
      "Hernia: 187 positive cases (0.43%)\n",
      "\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(94091) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(94092) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(94093) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(94094) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(94095) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(94096) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(94097) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(94098) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(94099) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(94100) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report, hamming_loss, jaccard_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Assuming df is your dataframe with features x0-x2048 and the 14 label columns\n",
    "# Separate features and labels\n",
    "X = df.filter(regex='^x\\d+')\n",
    "y = df[[\"Atelectasis\", \"Consolidation\", \"Infiltration\", \"Pneumothorax\", \"Edema\",\n",
    "       \"Emphysema\", \"Fibrosis\", \"Effusion\", \"Pneumonia\", \"Pleural_Thickening\",\n",
    "       \"Cardiomegaly\", \"Nodule\", \"Mass\", \"Hernia\"]]\n",
    "\n",
    "# Create a column indicating if all labels are 0 (no findings)\n",
    "y['no_finding'] = (y.sum(axis=1) == 0).astype(int)\n",
    "\n",
    "# Split the data first to avoid data leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y.drop('no_finding', axis=1),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y['no_finding']\n",
    ")\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}, Test data shape: {X_test.shape}\")\n",
    "\n",
    "# Scale the data before applying PCA\n",
    "print(\"Scaling data...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA\n",
    "print(\"Applying PCA...\")\n",
    "n_components = 100  # Starting point, adjust as needed\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Check explained variance\n",
    "explained_variance = np.sum(pca.explained_variance_ratio_)\n",
    "print(f\"Total explained variance with {n_components} components: {explained_variance:.4f}\")\n",
    "\n",
    "# Handle class imbalance by sampling\n",
    "print(\"Handling class imbalance...\")\n",
    "no_findings = y_train.sum(axis=1) == 0\n",
    "X_train_no_findings = X_train_pca[no_findings]\n",
    "y_train_no_findings = y_train[no_findings]\n",
    "X_train_findings = X_train_pca[~no_findings]\n",
    "y_train_findings = y_train[~no_findings]\n",
    "\n",
    "# Sample only a portion of the no-findings records\n",
    "sample_size = int(len(X_train_no_findings) * 0.05)  # Adjust ratio as needed\n",
    "print(f\"Sampling {sample_size} from {len(X_train_no_findings)} no-findings cases\")\n",
    "indices = np.random.choice(len(X_train_no_findings), sample_size, replace=False)\n",
    "X_train_no_findings_sampled = X_train_no_findings[indices]\n",
    "y_train_no_findings_sampled = y_train_no_findings.iloc[indices]\n",
    "\n",
    "# Combine the sampled no-findings with all findings samples\n",
    "X_train_balanced = np.vstack([X_train_no_findings_sampled, X_train_findings])\n",
    "y_train_balanced = pd.concat([y_train_no_findings_sampled, y_train_findings])\n",
    "\n",
    "# Shuffle the balanced data\n",
    "X_train_balanced, y_train_balanced = shuffle(\n",
    "    X_train_balanced, y_train_balanced, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Balanced training data shape: {X_train_balanced.shape}\")\n",
    "print(f\"Class distribution in balanced training data:\")\n",
    "for col in y_train_balanced.columns:\n",
    "    count = y_train_balanced[col].sum()\n",
    "    print(f\"{col}: {count} positive cases ({count/len(y_train_balanced)*100:.2f}%)\")\n",
    "\n",
    "# Define a function to train, predict and evaluate models\n",
    "def train_evaluate_model(clf, model_name, X_train, y_train, X_test, y_test):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    multi_clf = MultiOutputClassifier(clf, n_jobs=-1)\n",
    "    multi_clf.fit(X_train, y_train)\n",
    "    print(f\"{model_name} training completed in {time.time() - start_time:.2f} seconds!\")\n",
    "    \n",
    "    # Predict\n",
    "    print(f\"Generating predictions for {model_name}...\")\n",
    "    y_pred = multi_clf.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f\"\\nEvaluation metrics for {model_name}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Convert test data to array format if needed\n",
    "    y_test_array = y_test.values if hasattr(y_test, 'values') else np.array(y_test)\n",
    "    \n",
    "    # Multi-label metrics\n",
    "    hamming = hamming_loss(y_test_array, y_pred)\n",
    "    jaccard = jaccard_score(y_test_array, y_pred, average='samples')\n",
    "    \n",
    "    print(f\"Hamming Loss: {hamming:.4f} (lower is better)\")\n",
    "    print(f\"Jaccard Score: {jaccard:.4f} (higher is better)\")\n",
    "    \n",
    "    # Per-class metrics\n",
    "    class_metrics = {}\n",
    "    for i, label in enumerate(y_test.columns):\n",
    "        print(f\"\\nClassification report for {label}:\")\n",
    "        report = classification_report(y_test_array[:, i], y_pred[:, i], zero_division=0, output_dict=True)\n",
    "        print(classification_report(y_test_array[:, i], y_pred[:, i], zero_division=0))\n",
    "        \n",
    "        # Store metrics for this class\n",
    "        if '1' in report:  # Check if we have metrics for the positive class\n",
    "            class_metrics[label] = {\n",
    "                'precision': report['1']['precision'],\n",
    "                'recall': report['1']['recall'],\n",
    "                'f1-score': report['1']['f1-score'],\n",
    "                'support': report['1']['support']\n",
    "            }\n",
    "        else:\n",
    "            class_metrics[label] = {\n",
    "                'precision': 0,\n",
    "                'recall': 0,\n",
    "                'f1-score': 0,\n",
    "                'support': sum(y_test_array[:, i] == 1)\n",
    "            }\n",
    "    \n",
    "    # Overall metrics for positive cases\n",
    "    correct_positives = 0\n",
    "    total_positives = 0\n",
    "    false_positives = 0\n",
    "    \n",
    "    for i in range(len(y_test_array)):\n",
    "        true_positives_in_example = np.logical_and(y_test_array[i] == 1, y_pred[i] == 1).sum()\n",
    "        total_positives_in_example = (y_test_array[i] == 1).sum()\n",
    "        false_positives_in_example = np.logical_and(y_test_array[i] == 0, y_pred[i] == 1).sum()\n",
    "        \n",
    "        correct_positives += true_positives_in_example\n",
    "        total_positives += total_positives_in_example\n",
    "        false_positives += false_positives_in_example\n",
    "    \n",
    "    positive_recall = correct_positives / total_positives if total_positives > 0 else 0\n",
    "    positive_precision = correct_positives / (correct_positives + false_positives) if (correct_positives + false_positives) > 0 else 0\n",
    "    positive_f1 = 2 * (positive_precision * positive_recall) / (positive_precision + positive_recall) if (positive_precision + positive_recall) > 0 else 0\n",
    "    \n",
    "    print(\"\\nOverall metrics for positive classes:\")\n",
    "    print(f\"Overall positive recall: {positive_recall:.4f}\")\n",
    "    print(f\"Overall positive precision: {positive_precision:.4f}\")\n",
    "    print(f\"Overall positive F1 score: {positive_f1:.4f}\")\n",
    "    \n",
    "    # Count examples with at least one positive prediction\n",
    "    examples_with_positives = np.sum(np.any(y_test_array == 1, axis=1))\n",
    "    examples_with_correct_positives = 0\n",
    "    \n",
    "    for i in range(len(y_test_array)):\n",
    "        if np.any(y_test_array[i] == 1) and np.any(np.logical_and(y_test_array[i] == 1, y_pred[i] == 1)):\n",
    "            examples_with_correct_positives += 1\n",
    "    \n",
    "    print(f\"\\nExamples with at least one positive label: {examples_with_positives}\")\n",
    "    print(f\"Examples with at least one correctly predicted positive: {examples_with_correct_positives}\")\n",
    "    \n",
    "    if examples_with_positives > 0:\n",
    "        positive_example_accuracy = examples_with_correct_positives / examples_with_positives\n",
    "        print(f\"Percentage of positive examples with at least one correct prediction: {positive_example_accuracy:.4f}\")\n",
    "    else:\n",
    "        positive_example_accuracy = 0\n",
    "    \n",
    "    # Save metrics in a dictionary for comparison\n",
    "    metrics = {\n",
    "        \"hamming_loss\": hamming,\n",
    "        \"jaccard_score\": jaccard,\n",
    "        \"positive_recall\": positive_recall,\n",
    "        \"positive_precision\": positive_precision,\n",
    "        \"positive_f1\": positive_f1,\n",
    "        \"positive_example_accuracy\": positive_example_accuracy,\n",
    "        \"class_metrics\": class_metrics\n",
    "    }\n",
    "    \n",
    "    return multi_clf, metrics\n",
    "\n",
    "# 1. Train Random Forest\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,  # Adjust based on RAM constraints\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight='balanced',  # Help with imbalance\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Train Gradient Boosting Classifier\n",
    "# Note: GradientBoostingClassifier doesn't support class_weight directly\n",
    "gb_classifier = GradientBoostingClassifier(\n",
    "    n_estimators=100,  # Adjust based on RAM constraints\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    subsample=0.8,  # Helps with both RAM usage and class imbalance\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train and evaluate models\n",
    "rf_model, rf_metrics = train_evaluate_model(\n",
    "    rf_classifier, \"Random Forest\", \n",
    "    X_train_balanced, y_train_balanced, \n",
    "    X_test_pca, y_test\n",
    ")\n",
    "\n",
    "gb_model, gb_metrics = train_evaluate_model(\n",
    "    gb_classifier, \"Gradient Boosting\", \n",
    "    X_train_balanced, y_train_balanced, \n",
    "    X_test_pca, y_test\n",
    ")\n",
    "\n",
    "# Compare models\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "models = [\"Random Forest\", \"Gradient Boosting\"]\n",
    "metric_names = [\"hamming_loss\", \"jaccard_score\", \"positive_recall\", \n",
    "                \"positive_precision\", \"positive_f1\", \"positive_example_accuracy\"]\n",
    "model_metrics = [rf_metrics, gb_metrics]\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = []\n",
    "for metric in metric_names:\n",
    "    row = {\n",
    "        'Metric': metric.replace('_', ' ').title(),\n",
    "        'Random Forest': model_metrics[0][metric],\n",
    "        'Gradient Boosting': model_metrics[1][metric]\n",
    "    }\n",
    "    comparison_data.append(row)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for i, metric in enumerate(metric_names):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    values = [model_metrics[j][metric] for j in range(len(models))]\n",
    "    \n",
    "    if metric == \"hamming_loss\":\n",
    "        title = f\"{metric.replace('_', ' ').title()} (lower is better)\"\n",
    "    else:\n",
    "        title = f\"{metric.replace('_', ' ').title()} (higher is better)\"\n",
    "    \n",
    "    plt.bar(models, values, color=['steelblue', 'darkorange'])\n",
    "    plt.title(title)\n",
    "    plt.ylim(0, max(1, max(values) * 1.2))  # Adjust y-limit for readability\n",
    "    \n",
    "    # Add values on top of bars\n",
    "    for j, v in enumerate(values):\n",
    "        plt.text(j, v + 0.02, f\"{v:.4f}\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png')\n",
    "plt.show()\n",
    "\n",
    "# Class-level comparison\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"CLASS-LEVEL COMPARISON (F1 Scores)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a dataframe for class-level metrics\n",
    "class_data = []\n",
    "for label in rf_metrics['class_metrics'].keys():\n",
    "    row = {\n",
    "        'Class': label,\n",
    "        'RF F1': rf_metrics['class_metrics'][label]['f1-score'],\n",
    "        'GB F1': gb_metrics['class_metrics'][label]['f1-score'],\n",
    "        'Support': rf_metrics['class_metrics'][label]['support']\n",
    "    }\n",
    "    class_data.append(row)\n",
    "\n",
    "class_df = pd.DataFrame(class_data).sort_values('Support', ascending=False)\n",
    "print(class_df.to_string(index=False))\n",
    "\n",
    "# Plot class-level F1 comparison\n",
    "plt.figure(figsize=(15, 8))\n",
    "classes = class_df['Class'].values\n",
    "rf_f1 = class_df['RF F1'].values\n",
    "gb_f1 = class_df['GB F1'].values\n",
    "\n",
    "x = np.arange(len(classes))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "rects1 = ax.bar(x - width/2, rf_f1, width, label='Random Forest')\n",
    "rects2 = ax.bar(x + width/2, gb_f1, width, label='Gradient Boosting')\n",
    "\n",
    "ax.set_ylabel('F1 Score')\n",
    "ax.set_title('Class-level F1 Scores Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "# Add labels on top of bars\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_f1_comparison.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCONCLUSION AND RECOMMENDATIONS:\")\n",
    "better_model = \"Random Forest\" if rf_metrics[\"positive_f1\"] > gb_metrics[\"positive_f1\"] else \"Gradient Boosting\"\n",
    "print(f\"- Based on positive class F1 score, {better_model} performs better overall\")\n",
    "print(\"- For future improvements, consider:\")\n",
    "print(\"  1. Adjusting the balancing ratio to increase positive class representation\")\n",
    "print(\"  2. Class-specific thresholding for prediction probabilities\")\n",
    "print(\"  3. Try advanced techniques like XGBoost or SMOTE for handling imbalance\")\n",
    "print(\"  4. Further hyperparameter tuning for the better performing model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xray-svc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
